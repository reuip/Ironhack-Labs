{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b9fb00",
   "metadata": {},
   "source": [
    "<font size='6'>**What's included in this notebook**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4424a494",
   "metadata": {},
   "source": [
    "\t1. Load files\n",
    "\t2. Standardize data\n",
    "\t\ta. Lowercase col\n",
    "\t\tb. Lowercase str\n",
    "\t\tc. Remove blank row/duplicates\n",
    "\t3. Merge files\n",
    "\t\ta. Inconsistent columns\n",
    "\t\tb. Rename columns\n",
    "\t\tc. Merge files\n",
    "\t4. Explore data\n",
    "\t\ta. Check accuracy of dtypes\n",
    "\t\tb. Review content by eye\n",
    "\t5. Missing data\n",
    "\t\ta. Check percent of missing values\n",
    "\t\tb. Remove weak columns\n",
    "\t\tc. Remove weak rows\n",
    "\t6. Standardize categorical\n",
    "\t\ta. Check category lists for consistency\n",
    "\t\tb. Correct cat lists if needed\n",
    "\t7. Fix missing numbers \n",
    "\t\ta. Replace missing with mean\n",
    "\t8. Output file to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cedaeb3",
   "metadata": {},
   "source": [
    "# Load file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ffed9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OneHotEncoder  ##. better to use dummy from pandas \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50\n",
    "import qgrid\n",
    "import glob\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "39585171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_dataframes(path):\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    dataframes_list=[]\n",
    "    file_count=len(all_files)\n",
    "    for i in range(file_count):\n",
    "        temp_df = pd.read_csv(all_files[i])\n",
    "        dataframes_list.append(temp_df)\n",
    "\n",
    "    return dataframes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e568a3d",
   "metadata": {},
   "source": [
    "# Standardize data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e1b2c",
   "metadata": {},
   "source": [
    "## Lowercase column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "fa68b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_lowercase(df):\n",
    "    '''Takes one value, dataframe, and changes all columns to lowercase\n",
    "    For easy comparison and merging of multiple dataframes'''\n",
    "    df_temp = [i.lower() for i in df.columns]\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11eebfb",
   "metadata": {},
   "source": [
    "## Lowercase all string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "58f19f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_lowercase(df):\n",
    "    '''Takes one value, dataframe, and changes all values that are strings to all lowercase\n",
    "    For easy identification of discrete values and for merging of dataframes'''\n",
    "    df=df.applymap(lambda x:x.lower() if type(x) == str else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd2f8c",
   "metadata": {},
   "source": [
    "## Removing duplicate and blank records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "356c752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates_and_blank_lines(df):\n",
    "    #Removes duplicates if entire row is the same\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    #Removes rows if they are completely blank\n",
    "    df.dropna(how=\"all\",axis=0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7700861a",
   "metadata": {},
   "source": [
    "# Merge files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344237f",
   "metadata": {},
   "source": [
    "## Check files for inconsistent columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "5098ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unique_columns(df_list):\n",
    "    #Gather column names from all files in a list\n",
    "\n",
    "    all_col_names=[]\n",
    "    temp_col_names=[]\n",
    "    unmatched_col_names=[]\n",
    "    unmatched_col_dict={}\n",
    "\n",
    "    for i in df_list:\n",
    "        [all_col_names.append(col) for col in i.columns]\n",
    "\n",
    "\n",
    "    #Remove duplicates to create a unique set of column names\n",
    "    unique_col_names=list(set(all_col_names))\n",
    "\n",
    "    #Check which files are missing which column names. Place these in a dictionary with key of file number.\n",
    "    file_num=1\n",
    "    for x in df_list:\n",
    "        [temp_col_names.append(col) for col in x.columns]\n",
    "        [unmatched_col_names.append(y) for y in unique_col_names if y not in temp_col_names]        \n",
    "        unmatched_col_dict[file_num]=unmatched_col_names\n",
    "        unmatched_col_names=[]\n",
    "        temp_col_names=[]\n",
    "        file_num+=1\n",
    "\n",
    "    return unmatched_col_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457959fa",
   "metadata": {},
   "source": [
    "## Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "be6b6eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_columns(df_list):\n",
    "    continue_loop=True\n",
    "    wrong_name_list=[]\n",
    "    right_name_list=[]\n",
    "    \n",
    "    while continue_loop==True:\n",
    "        wrong_name=input('What is the column name that you want to fix? (none if done)')\n",
    "        if wrong_name.lower()!=\"none\":\n",
    "            right_name=input('What is the correct column name? (none to cancel)')\n",
    "            if right_name.lower()!='none':\n",
    "                wrong_name_list.append(wrong_name)\n",
    "                right_name_list.append(right_name)\n",
    "            else:\n",
    "                continue_loop=False\n",
    "        else:\n",
    "            continue_loop=False\n",
    "    if len(wrong_name_list)>0:\n",
    "        for i in df_list:\n",
    "            col_rename_dic=dict(zip(wrong_name_list,right_name_list))\n",
    "            i.rename(columns=col_rename_dic,inplace=True)\n",
    "    return df_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c3406",
   "metadata": {},
   "source": [
    "## Merge files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4eeff036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_files(df_list):\n",
    "    df=pd.concat(df_list,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f75a4",
   "metadata": {},
   "source": [
    "# Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79095f72",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc949721",
   "metadata": {},
   "source": [
    "## Check percent of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "efb3dee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate percent of missing values\n",
    "def count_missing_values(df):\n",
    "    missing_val=df.isnull().sum()\n",
    "    all_val=df.count()\n",
    "    missing_ratio=missing_val/all_val\n",
    "    return missing_ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1d318a",
   "metadata": {},
   "source": [
    "## Drop columns with too few values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "157a6ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df,drop_list):\n",
    "    for i in drop_list:\n",
    "        df.drop(drop_list, axis = 1, inplace = True) \n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190daed7",
   "metadata": {},
   "source": [
    "## Drop rows with too many NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "9bb9330a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#No code as its one line and needs no specific function to run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7559e91",
   "metadata": {},
   "source": [
    "## Find missing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5fcb9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_columns_with_nan(df):\n",
    "    # This creates a list ## integers_with_nan ## which is a list of numerical columns with blanks in them.  \n",
    "    col_list=[]\n",
    "    col_list=df.columns\n",
    "    integers_with_nan=[]\n",
    "    for i in col_list:\n",
    "        if df[i].isnull().values.any()==True:\n",
    "            if df[i].dtype!='O':\n",
    "                integers_with_nan.append(i)\n",
    "    return integers_with_nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff78d8",
   "metadata": {},
   "source": [
    "# Standardize categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee3fd8",
   "metadata": {},
   "source": [
    "## Check categorical columns for misspellings or issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0290c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a copy of the dataframe for string-based columns only.  \n",
    "# Then, creates a dictionary of the column (key) plus array of values (value) to show the results\n",
    "def check_categoricals(df):\n",
    "    categorical_df=df.select_dtypes(object)\n",
    "    unique_dict={col: categorical_df[col].unique() for col in categorical_df}\n",
    "    return unique_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79432862",
   "metadata": {},
   "source": [
    "## Standardizing categorical byreplacing values with new ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "86a5710d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_categorical_names(df,a):\n",
    "#Requires 'a' to be filled in\n",
    "\n",
    "# Creates a dictionary 'a' of values to correct.  \n",
    "# Outer dictionary is the column to correct\n",
    "# Inner dictionary key is the correct spelling, then list (dictionary value) is the incorrect spellings to find and replace\n",
    "\n",
    "#This code will run through the dictionary 'a' and update string values in the dataframe\n",
    "#Using the new string values\n",
    "    for key in a.keys():\n",
    "        for key2 in a[key].keys():\n",
    "            list_values=a[key][key2]\n",
    "            df.loc[df[str(key)].isin(list_values),key]=str(key2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4929027",
   "metadata": {},
   "source": [
    "# Fix missing numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0fcc77",
   "metadata": {},
   "source": [
    "## Replace missing numbers with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ca5722cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nan_integer_with_mean(df,integers_with_nan):\n",
    "    #Fill missing numbers with the average of the column\n",
    "    for j in integers_with_nan:\n",
    "        temp_mean=np.mean(df[j])\n",
    "        df[j]=df[j].fillna(temp_mean)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00344d3e",
   "metadata": {},
   "source": [
    "# Output file to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e62a2443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_file(folder_path,df):\n",
    "    csv_file_name=input(\"What do you want to name the new file?\")\n",
    "    output_path=folder_path+ \"\\\\\" +csv_file_name+'.csv'\n",
    "    df.to_csv(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559a9797",
   "metadata": {},
   "source": [
    "# Working Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a600a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['state'], 2: ['state'], 3: ['st']}\n",
      "What is the column name that you want to fix? (none if done)st\n",
      "What is the correct column name? (none to cancel)state\n",
      "What is the column name that you want to fix? (none if done)none\n",
      "{'customer': array(['rb50392', 'qz44356', 'ai49188', ..., 'td14365', 'up19263',\n",
      "       'y167826'], dtype=object), 'state': array(['washington', 'arizona', 'nevada', 'california', 'oregon', 'cali',\n",
      "       'az', 'wa'], dtype=object), 'gender': array([nan, 'f', 'm', 'femal', 'male', 'female'], dtype=object), 'education': array(['master', 'bachelor', 'high school or below', 'college',\n",
      "       'bachelors', 'doctor'], dtype=object), 'customer lifetime value': array([nan, '697953.59%', '1288743.17%', ..., 8163.890428, 7524.442436,\n",
      "       2611.836866], dtype=object), 'number of open complaints': array(['1/0/00', '1/2/00', '1/1/00', '1/3/00', '1/5/00', '1/4/00', 0, 2,\n",
      "       3, 1, 5, 4], dtype=object), 'policy type': array(['personal auto', 'corporate auto', 'special auto'], dtype=object), 'vehicle class': array(['four-door car', 'two-door car', 'suv', 'luxury suv', 'sports car',\n",
      "       'luxury car'], dtype=object)}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "####1. Load relevant csv files. \n",
    "### INPUT -- folder_path for file\n",
    "\n",
    "# Update folder_path to grab all csv files in folder\n",
    "folder_path = r'C:\\Users\\MichaelTaylo_c9zoof3\\Documents\\GitHub\\Ironhack-Labs\\People Analytics\\Data'\n",
    "\n",
    "df_list=load_csv_dataframes(folder_path)\n",
    "\n",
    "\n",
    "####2. Clean and standardize data\n",
    "for i in df_list:\n",
    "    \n",
    "    #a. Lowercase columns\n",
    "    i.columns=col_lowercase(i)\n",
    "    \n",
    "    #b. Lowercase string values\n",
    "    i.update(string_lowercase(i))\n",
    "    \n",
    "    #c. Removes blank rows and duplicate records\n",
    "    drop_duplicates_and_blank_lines(i)\n",
    "\n",
    "####3. Merge files\n",
    "if len(df_list)>1:\n",
    "    #a. Check which columns are inconsistent across files\n",
    "    print(list_unique_columns(df_list))\n",
    "\n",
    "    #b. Rename columns\n",
    "    df_list=rename_columns(df_list)\n",
    "\n",
    "    #c. Merge files\n",
    "    merge_files(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "eaa9af98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9137 entries, 0 to 9136\n",
      "Data columns (total 11 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   customer                   9137 non-null   object \n",
      " 1   state                      9137 non-null   object \n",
      " 2   gender                     9015 non-null   object \n",
      " 3   education                  9137 non-null   object \n",
      " 4   customer lifetime value    9130 non-null   object \n",
      " 5   income                     9137 non-null   float64\n",
      " 6   monthly premium auto       9137 non-null   float64\n",
      " 7   number of open complaints  9137 non-null   object \n",
      " 8   policy type                9137 non-null   object \n",
      " 9   vehicle class              9137 non-null   object \n",
      " 10  total claim amount         9137 non-null   float64\n",
      "dtypes: float64(3), object(8)\n",
      "memory usage: 785.3+ KB\n"
     ]
    }
   ],
   "source": [
    "####4. Explore data -- review data by eye\n",
    "\n",
    "#a. Check data types for accuracy\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7409a327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb41fd9f631b45b4951714b0246d22be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': False, 'defaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#b. Review content by eye. Check for problems.\n",
    "qgrid.show_grid(df,grid_options={'forceFitColumns': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e886d392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer                     0.000000\n",
       "state                        0.000000\n",
       "gender                       0.013533\n",
       "education                    0.000000\n",
       "customer lifetime value      0.000767\n",
       "income                       0.000000\n",
       "monthly premium auto         0.000000\n",
       "number of open complaints    0.000000\n",
       "policy type                  0.000000\n",
       "vehicle class                0.000000\n",
       "total claim amount           0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####5. Missing data\n",
    "\n",
    "#a. Check missing value percentage to decide what to do with them\n",
    "count_missing_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b7dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPTIONAL \n",
    "#b. Drop columns due to high NaN.  Fill in 'drop_list' with columns you want to drop before running it\n",
    "### INPUT -- drop_list of columns to drop\n",
    "\n",
    "drop_list=[]\n",
    "\n",
    "drop_columns(df,drop_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f40f650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#OPTIONAL \n",
    "#c. Remove rows with Nans.  Keeps rows with at least so many values.  You can change the 'keep' threshold by updating the 'threshold_percent'\n",
    "### INPUT -- threshold percent of rows to drop\n",
    "\n",
    "threshold_percent=.5\n",
    "\n",
    "drop_threshold=math.floor(len(df.columns)*threshold_percent)\n",
    "df.dropna(axis=0,thresh=drop_threshold,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a71213",
   "metadata": {},
   "outputs": [],
   "source": [
    "####6. Standardize Categorical\n",
    "\n",
    "#a. Get current list of categorical values per column.  Check to see which need to be normalized\n",
    "check_categoricals(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aeaa17",
   "metadata": {},
   "outputs": [],
   "source": [
    "### OPTIONAL \n",
    "###b. Provide correct standards so that old values are re-written with new ones\n",
    "### INPUT -- a dictionary of values\n",
    "\n",
    "a={\n",
    "    'sex':\n",
    "        {'female':['f','femal'],\n",
    "        'male':['male','m']}\n",
    "}\n",
    "\n",
    "standardize_categorical_names(df,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91772b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "####7. Fix missing numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64f5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "###OPTIONAL\n",
    "###a. Replace blank with mean\n",
    "### INPUT -- integers_with_nan if you want special list vs all integer columns\n",
    "\n",
    "\n",
    "# Change missing number with mean.  If you want to apply to all integer columns, use first function below.  \n",
    "# Otherwise, comment it out and customize the list.\n",
    "\n",
    "#Gather all integer columns with NaN.\n",
    "integers_with_nan=get_columns_with_nan(df)\n",
    "#integers_with_nan=[list]\n",
    "\n",
    "\n",
    "#Replace missing numbers with mean\n",
    "df=replace_nan_integer_with_mean(df,integers_with_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6c388618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you want to name the new file?test2\n"
     ]
    }
   ],
   "source": [
    "####8. Output dataframe to csv file\n",
    "output_file(folder_path,df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "430.417px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "292.844px",
    "left": "996px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
