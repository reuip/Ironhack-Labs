{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffed9f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OneHotEncoder  ##. better to use dummy from pandas \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50\n",
    "import qgrid\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a600a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['state'], 2: ['state'], 3: ['st']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####1. Load relevant csv files. \n",
    "\n",
    "# Update folder_path to grab all csv files in folder\n",
    "folder_path = r'C:\\Users\\MichaelTaylo_c9zoof3\\Documents\\GitHub\\Ironhack-Labs\\People Analytics\\Data'\n",
    "df_list=load_csv_dataframes(folder_path)\n",
    "\n",
    "\n",
    "####2. Clean and standardize data\n",
    "for i in df_list:\n",
    "    \n",
    "    # Lowercase columns\n",
    "    i.columns=col_lowercase(i)\n",
    "    \n",
    "    # Lowercase string values\n",
    "    i.update(string_lowercase(i))\n",
    "    \n",
    "    # Removes blank rows and duplicate records\n",
    "    drop_duplicates_and_blank_lines(i)\n",
    "\n",
    "####3. Merge files\n",
    "\n",
    "# Check which columns are inconsistent across files\n",
    "print(list_unique_columns(df_list))\n",
    "\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2df4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e285b025",
   "metadata": {},
   "source": [
    "# Prepare environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5287a4b",
   "metadata": {},
   "source": [
    "## Imports and load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e6dd28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import quantile_transform\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import OneHotEncoder  ##. better to use dummy from pandas \n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50\n",
    "import qgrid\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cedaeb3",
   "metadata": {},
   "source": [
    "## Load relevant dataframe from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39585171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_dataframes(path):\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    dataframes_list=[]\n",
    "    file_count=len(all_files)\n",
    "    for i in range(file_count):\n",
    "        temp_df = pd.read_csv(all_files[i])\n",
    "        dataframes_list.append(temp_df)\n",
    "\n",
    "    return dataframes_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e568a3d",
   "metadata": {},
   "source": [
    "# Quick clean and standardizing data (e.g. lowercase titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396e1b2c",
   "metadata": {},
   "source": [
    "## Lowercase column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa68b908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_lowercase(df):\n",
    "    '''Takes one value, dataframe, and changes all columns to lowercase\n",
    "    For easy comparison and merging of multiple dataframes'''\n",
    "    df_temp = [i.lower() for i in df.columns]\n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11eebfb",
   "metadata": {},
   "source": [
    "## Lowercase all string values in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58f19f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def string_lowercase(df):\n",
    "    '''Takes one value, dataframe, and changes all values that are strings to all lowercase\n",
    "    For easy identification of discrete values and for merging of dataframes'''\n",
    "    df=df.applymap(lambda x:x.lower() if type(x) == str else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fd2f8c",
   "metadata": {},
   "source": [
    "## Removing duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356c752f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates_and_blank_lines(df):\n",
    "    #Removes duplicates if entire row is the same\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    #Removes rows if they are completely blank\n",
    "    df.dropna(how=\"all\",axis=0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7700861a",
   "metadata": {},
   "source": [
    "# Merging files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344237f",
   "metadata": {},
   "source": [
    "## Check files for unique columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5098ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_unique_columns(df_list):\n",
    "    #Gather column names from all files in a list\n",
    "\n",
    "    all_col_names=[]\n",
    "    temp_col_names=[]\n",
    "    unmatched_col_names=[]\n",
    "    unmatched_col_dict={}\n",
    "\n",
    "    for i in df_list:\n",
    "        [all_col_names.append(col) for col in i.columns]\n",
    "\n",
    "\n",
    "    #Remove duplicates to create a unique set of column names\n",
    "    unique_col_names=list(set(all_col_names))\n",
    "\n",
    "    #Check which files are missing which column names. Place these in a dictionary with key of file number.\n",
    "    file_num=1\n",
    "    for x in df_list:\n",
    "        [temp_col_names.append(col) for col in x.columns]\n",
    "        [unmatched_col_names.append(y) for y in unique_col_names if y not in temp_col_names]        \n",
    "        unmatched_col_dict[file_num]=unmatched_col_names\n",
    "        unmatched_col_names=[]\n",
    "        temp_col_names=[]\n",
    "        file_num+=1\n",
    "\n",
    "    return unmatched_col_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457959fa",
   "metadata": {},
   "source": [
    "## Space to do renaming of columns <font color='red'>(Need input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac0db5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If quick renaming of fles, can use the dictionary form. Change ##df## to dataframe name.\n",
    "for i in file_list:\n",
    "    i.rename(columns={\"st\":\"state\",},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "17108dc2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'zip' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [27]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m zip_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mzip\u001b[39m(old_names,new_names)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m file_list:\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzip_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\core\\frame.py:5083\u001b[0m, in \u001b[0;36mDataFrame.rename\u001b[1;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[0;32m   4964\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrename\u001b[39m(\n\u001b[0;32m   4965\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4966\u001b[0m     mapper: Renamer \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4974\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   4975\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4976\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4977\u001b[0m \u001b[38;5;124;03m    Alter axes labels.\u001b[39;00m\n\u001b[0;32m   4978\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5081\u001b[0m \u001b[38;5;124;03m    4  3  6\u001b[39;00m\n\u001b[0;32m   5082\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5083\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_rename\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5084\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5085\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5086\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5087\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5088\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5089\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5090\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5091\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5092\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\core\\generic.py:1155\u001b[0m, in \u001b[0;36mNDFrame._rename\u001b[1;34m(self, mapper, index, columns, axis, copy, inplace, level, errors)\u001b[0m\n\u001b[0;32m   1148\u001b[0m         missing_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   1149\u001b[0m             label\n\u001b[0;32m   1150\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m index, label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(replacements)\n\u001b[0;32m   1151\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m indexer[index] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1152\u001b[0m         ]\n\u001b[0;32m   1153\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_labels\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1155\u001b[0m new_index \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1156\u001b[0m result\u001b[38;5;241m.\u001b[39m_set_axis_nocheck(new_index, axis\u001b[38;5;241m=\u001b[39maxis_no, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1157\u001b[0m result\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6131\u001b[0m, in \u001b[0;36mIndex._transform_index\u001b[1;34m(self, func, level)\u001b[0m\n\u001b[0;32m   6129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_tuples(items, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)\n\u001b[0;32m   6130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 6131\u001b[0m     items \u001b[38;5;241m=\u001b[39m [func(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m]\n\u001b[0;32m   6132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(items, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   6129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_tuples(items, names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)\n\u001b[0;32m   6130\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 6131\u001b[0m     items \u001b[38;5;241m=\u001b[39m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m]\n\u001b[0;32m   6132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Index(items, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname, tupleize_cols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'zip' object is not callable"
     ]
    }
   ],
   "source": [
    "#If need more complex format, then can use a zip instead. Change ##df## to dataframe name.\n",
    "old_names={'a','b','c'}\n",
    "new_names={'x','y','z'}\n",
    "zip_file=zip(old_names,new_names)\n",
    "\n",
    "for i in file_list:\n",
    "    i.rename(columns=zip_file,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284c3406",
   "metadata": {},
   "source": [
    "## Merging of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4eeff036",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat(file_list,axis=0,ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62f75a4",
   "metadata": {},
   "source": [
    "# Replace missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7559e91",
   "metadata": {},
   "source": [
    "## Replace missing numbers with mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5fcb9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a list ## integers_with_nan ## which is a list of numerical columns with blanks in them.  \n",
    "#The next parts will give you options for how to handle the blanks\n",
    "\n",
    "col_list=[]\n",
    "col_list=df.columns\n",
    "integers_with_nan=[]\n",
    "for i in col_list:\n",
    "    if df[i].isnull().values.any()==True:\n",
    "        if df[i].dtype!='O':\n",
    "            integers_with_nan.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aa334d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill missing numbers with the average of the column\n",
    "for j in integers_with_nan:\n",
    "    temp_mean=np.mean(df[j])\n",
    "    df[j]=df[j].fillna(temp_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ff78d8",
   "metadata": {},
   "source": [
    "# Review data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f411cd0",
   "metadata": {},
   "source": [
    "## Check data types and blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3476654a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54877 entries, 0 to 54876\n",
      "Data columns (total 52 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   Unnamed: 0                     54877 non-null  float64\n",
      " 1   Customer                       20047 non-null  object \n",
      " 2   State                          17349 non-null  object \n",
      " 3   Customer Lifetime Value        20040 non-null  object \n",
      " 4   Response                       10279 non-null  object \n",
      " 5   Coverage                       10910 non-null  object \n",
      " 6   Education                      20047 non-null  object \n",
      " 7   Effective To Date              10910 non-null  object \n",
      " 8   EmploymentStatus               10910 non-null  object \n",
      " 9   Gender                         17980 non-null  object \n",
      " 10  Income                         54877 non-null  float64\n",
      " 11  Location Code                  10910 non-null  object \n",
      " 12  Marital Status                 10910 non-null  object \n",
      " 13  Monthly Premium Auto           54877 non-null  float64\n",
      " 14  Months Since Last Claim        54877 non-null  float64\n",
      " 15  Months Since Policy Inception  54877 non-null  float64\n",
      " 16  Number of Open Complaints      19414 non-null  object \n",
      " 17  Number of Policies             54877 non-null  float64\n",
      " 18  Policy Type                    20047 non-null  object \n",
      " 19  Policy                         10910 non-null  object \n",
      " 20  Renew Offer Type               10910 non-null  object \n",
      " 21  Sales Channel                  10910 non-null  object \n",
      " 22  Total Claim Amount             54877 non-null  float64\n",
      " 23  Vehicle Class                  19425 non-null  object \n",
      " 24  Vehicle Size                   10288 non-null  object \n",
      " 25  Vehicle Type                   5428 non-null   object \n",
      " 26  region                         31893 non-null  object \n",
      " 27  customer_lifetime_value        54877 non-null  float64\n",
      " 28  response                       31893 non-null  object \n",
      " 29  coverage                       31893 non-null  object \n",
      " 30  education                      31893 non-null  object \n",
      " 31  effective_to_date              31893 non-null  object \n",
      " 32  month                          10689 non-null  object \n",
      " 33  employment_status              31893 non-null  object \n",
      " 34  gender                         31893 non-null  object \n",
      " 35  income                         54877 non-null  float64\n",
      " 36  location_code                  31893 non-null  object \n",
      " 37  marital_status                 31893 non-null  object \n",
      " 38  monthly_premium_auto           54877 non-null  float64\n",
      " 39  months_since_last_claim        54877 non-null  float64\n",
      " 40  months_since_policy_inception  54877 non-null  float64\n",
      " 41  number_of_open_complaints      54877 non-null  float64\n",
      " 42  number_of_policies             54877 non-null  float64\n",
      " 43  policy_type                    31893 non-null  object \n",
      " 44  policy                         31893 non-null  object \n",
      " 45  renew_offer_type               31893 non-null  object \n",
      " 46  sales_channel                  31893 non-null  object \n",
      " 47  total_claim_amount             54877 non-null  float64\n",
      " 48  vehicle_class                  31893 non-null  object \n",
      " 49  vehicle_size                   31893 non-null  object \n",
      " 50  ST                             2067 non-null   object \n",
      " 51  GENDER                         1945 non-null   object \n",
      "dtypes: float64(15), object(37)\n",
      "memory usage: 21.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5493c90e",
   "metadata": {},
   "source": [
    "## Eyeball check data for issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "626d36db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599c1ad54924482ca34b65c0bd8a00dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': False, 'defaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qgrid.show_grid(df,grid_options={'forceFitColumns': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f766cf9",
   "metadata": {},
   "source": [
    "# Fix categorical values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee3fd8",
   "metadata": {},
   "source": [
    "## Check categorical columns for misspellings or issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0290c679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Customer': array(['DK49336', 'KX64629', 'LZ68649', ..., 'TL39050', 'WA60547', nan],\n",
       "       dtype=object),\n",
       " 'State': array(['Arizona', 'California', 'Washington', 'Oregon', nan, 'Nevada'],\n",
       "       dtype=object),\n",
       " 'Customer Lifetime Value': array([4809.21696, 2228.525238, 14947.9173, ..., '568964.41%',\n",
       "        '368672.38%', '399258.39%'], dtype=object),\n",
       " 'Response': array(['No', 'Yes', nan], dtype=object),\n",
       " 'Coverage': array(['Basic', 'Extended', 'Premium', nan], dtype=object),\n",
       " 'Education': array(['College', 'Bachelor', 'High School or Below', 'Doctor', 'Master',\n",
       "        nan, 'Bachelors'], dtype=object),\n",
       " 'Effective To Date': array(['2/18/11', '1/18/11', '2/10/11', '1/11/11', '1/17/11', '2/14/11',\n",
       "        '2/24/11', '1/19/11', '1/4/11', '1/2/11', '2/7/11', '1/31/11',\n",
       "        '1/26/11', '2/28/11', '1/16/11', '2/26/11', '2/23/11', '1/15/11',\n",
       "        '2/2/11', '2/15/11', '1/24/11', '2/21/11', '2/22/11', '1/7/11',\n",
       "        '1/28/11', '2/8/11', '2/12/11', '2/20/11', '1/5/11', '2/19/11',\n",
       "        '1/3/11', '2/3/11', '1/22/11', '1/23/11', '2/5/11', '2/13/11',\n",
       "        '1/25/11', '2/16/11', '2/1/11', '1/27/11', '1/12/11', '1/20/11',\n",
       "        '2/6/11', '2/11/11', '1/21/11', '1/29/11', '1/9/11', '2/9/11',\n",
       "        '2/27/11', '1/1/11', '2/17/11', '2/25/11', '1/13/11', '1/6/11',\n",
       "        '2/4/11', '1/14/11', '1/10/11', '1/8/11', '1/30/11', nan],\n",
       "       dtype=object),\n",
       " 'EmploymentStatus': array(['Employed', 'Unemployed', 'Medical Leave', 'Disabled', 'Retired',\n",
       "        nan], dtype=object),\n",
       " 'Gender': array(['M', 'F', nan], dtype=object),\n",
       " 'Location Code': array(['Suburban', 'Urban', 'Rural', nan], dtype=object),\n",
       " 'Marital Status': array(['Married', 'Single', 'Divorced', nan], dtype=object),\n",
       " 'Number of Open Complaints': array([0.0, nan, 3.0, 1.0, 2.0, 4.0, 5.0, '1/0/00', '1/2/00', '1/1/00',\n",
       "        '1/3/00', '1/5/00', '1/4/00'], dtype=object),\n",
       " 'Policy Type': array(['Corporate Auto', 'Personal Auto', 'Special Auto', nan],\n",
       "       dtype=object),\n",
       " 'Policy': array(['Corporate L3', 'Personal L3', 'Personal L2', 'Corporate L2',\n",
       "        'Personal L1', 'Special L1', 'Corporate L1', 'Special L3',\n",
       "        'Special L2', nan], dtype=object),\n",
       " 'Renew Offer Type': array(['Offer3', 'Offer4', 'Offer2', 'Offer1', nan], dtype=object),\n",
       " 'Sales Channel': array(['Agent', 'Call Center', 'Branch', 'Web', nan], dtype=object),\n",
       " 'Vehicle Class': array(['Four-Door Car', 'SUV', 'Two-Door Car', 'Sports Car', 'Luxury Car',\n",
       "        'Luxury SUV', nan], dtype=object),\n",
       " 'Vehicle Size': array(['Medsize', 'Small', 'Large', nan], dtype=object),\n",
       " 'Vehicle Type': array([nan, 'A'], dtype=object),\n",
       " 'region': array([nan, 'central', 'west region', 'east', 'north west', 'arizona',\n",
       "        'california', 'washington', 'oregon', 'nevada'], dtype=object),\n",
       " 'response': array([nan, 'no', 'yes'], dtype=object),\n",
       " 'coverage': array([nan, 'basic', 'extended', 'premium'], dtype=object),\n",
       " 'education': array([nan, 'college', 'bachelor', 'high school or below', 'doctor',\n",
       "        'master'], dtype=object),\n",
       " 'effective_to_date': array([nan, '2/18/11', '1/18/11', '2/10/11', '1/11/11', '1/17/11',\n",
       "        '2/14/11', '2/24/11', '1/19/11', '1/4/11', '1/2/11', '2/7/11',\n",
       "        '1/31/11', '1/26/11', '2/28/11', '1/16/11', '2/26/11', '2/23/11',\n",
       "        '1/15/11', '2/2/11', '2/15/11', '1/24/11', '2/21/11', '2/22/11',\n",
       "        '1/7/11', '1/28/11', '2/8/11', '2/12/11', '2/20/11', '1/5/11',\n",
       "        '2/19/11', '1/3/11', '2/3/11', '1/22/11', '1/23/11', '2/5/11',\n",
       "        '2/13/11', '1/25/11', '2/16/11', '2/1/11', '1/27/11', '1/12/11',\n",
       "        '1/20/11', '2/6/11', '2/11/11', '1/21/11', '1/29/11', '1/9/11',\n",
       "        '2/9/11', '2/27/11', '1/1/11', '2/17/11', '2/25/11', '1/13/11',\n",
       "        '1/6/11', '2/4/11', '1/14/11', '1/10/11', '1/8/11', '1/30/11'],\n",
       "       dtype=object),\n",
       " 'month': array([nan, 'feb', 'jan'], dtype=object),\n",
       " 'employment_status': array([nan, 'employed', 'unemployed', 'medical leave', 'disabled',\n",
       "        'retired'], dtype=object),\n",
       " 'gender': array([nan, 'm', 'f'], dtype=object),\n",
       " 'location_code': array([nan, 'suburban', 'urban', 'rural'], dtype=object),\n",
       " 'marital_status': array([nan, 'married', 'single', 'divorced'], dtype=object),\n",
       " 'policy_type': array([nan, 'corporate auto', 'personal auto', 'special auto'],\n",
       "       dtype=object),\n",
       " 'policy': array([nan, 'corporate l3', 'personal l3', 'personal l2', 'corporate l2',\n",
       "        'personal l1', 'special l1', 'corporate l1', 'special l3',\n",
       "        'special l2'], dtype=object),\n",
       " 'renew_offer_type': array([nan, 'offer3', 'offer4', 'offer2', 'offer1'], dtype=object),\n",
       " 'sales_channel': array([nan, 'agent', 'call center', 'branch', 'web'], dtype=object),\n",
       " 'vehicle_class': array([nan, 'four-door car', 'suv', 'two-door car', 'sports car',\n",
       "        'luxury car', 'luxury suv'], dtype=object),\n",
       " 'vehicle_size': array([nan, 'medsize', 'small', 'large'], dtype=object),\n",
       " 'ST': array([nan, 'Washington', 'Arizona', 'Nevada', 'California', 'Oregon',\n",
       "        'Cali', 'AZ', 'WA'], dtype=object),\n",
       " 'GENDER': array([nan, 'F', 'M', 'Femal', 'Male', 'female'], dtype=object)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creates a copy of the dataframe for string-based columns only.  \n",
    "# Then, creates a dictionary of the column (key) plus array of values (value) to show the results\n",
    "categorical_df=df.select_dtypes(object)\n",
    "unique_dict={col: categorical_df[col].unique() for col in categorical_df}\n",
    "unique_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79432862",
   "metadata": {},
   "source": [
    "## Fix categorical values by replacing values with new ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102aca6c",
   "metadata": {},
   "source": [
    "### Replace a list of terms with one standard version <font color='red'>(Need input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86a5710d",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sex'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\_libs\\index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sex'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key2 \u001b[38;5;129;01min\u001b[39;00m a[key]\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     18\u001b[0m     list_values\u001b[38;5;241m=\u001b[39ma[key][key2]\n\u001b[1;32m---> 19\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misin(list_values),key]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(key2)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\DA_Env\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'sex'"
     ]
    }
   ],
   "source": [
    "#Fill in 'a' below\n",
    "\n",
    "# Creates a dictionary ##a## of values to correct.  \n",
    "# Outer dictionary is the column to correct\n",
    "# Inner dictionary key is the correct spelling, then list (dictionary value) is the incorrect spellings to find and replace\n",
    "\n",
    "a={\n",
    "    'sex':\n",
    "        {'female':['f','femal'],\n",
    "        'male':['male','m']}\n",
    "}\n",
    "\n",
    "\n",
    "#This code will run through the dictionary a and update string values in the dataframe\n",
    "#Using the new string values\n",
    "for key in a.keys():\n",
    "    for key2 in a[key].keys():\n",
    "        list_values=a[key][key2]\n",
    "        df.loc[df[str(key)].isin(list_values),key]=str(key2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05438031",
   "metadata": {},
   "source": [
    "### Replace terms 1:1 with an alternative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2e7bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in these three with correct values, then run to update a column with new values.\n",
    "original_version=['f','m']          #List in order of terms in column to change\n",
    "new_version=['female','male']       #List in order of original version list of new terms to use\n",
    "column_name='gender'                #Column name to use in action\n",
    "\n",
    "replace_map=dict(zip(original_version,new_version))\n",
    "\n",
    "df[column_name].replace(replace_map,inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "388.941px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "292.844px",
    "left": "996px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
